{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import unicodedata\n",
    "\n",
    "def normalize(s: str):\n",
    "    return unicodedata.normalize(\"NFC\", s)\n",
    "\n",
    "f = open(\"./data/GSM8K/train.jsonl\", \"r\")\n",
    "data = []\n",
    "for line in f:\n",
    "    line = json.loads(line)\n",
    "    line[\"question\"] = normalize(line[\"question\"])\n",
    "    answer = normalize(line[\"answer\"]).split(\"####\")[-1]\n",
    "    line[\"answer\"] = float(answer.replace(\",\", \"\").strip())\n",
    "    data.append(line)\n",
    "\n",
    "f.close()\n",
    "\n",
    "f = open(\"./data/GSM8K/test.jsonl\", \"r\")\n",
    "for line in f:\n",
    "    line = json.loads(line)\n",
    "    line[\"question\"] = normalize(line[\"question\"])\n",
    "    answer = normalize(line[\"answer\"]).split(\"####\")[-1]\n",
    "    line[\"answer\"] = float(answer.replace(\",\", \"\").strip())\n",
    "    data.append(line)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8792"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./data/GSM8K/gsm6k_code.jsonl\", \"r\")\n",
    "code_data = []\n",
    "for line in f:\n",
    "    line = json.loads(line)\n",
    "    line[\"question\"] = normalize(line[\"question\"])\n",
    "    code_data.append(line)\n",
    "\n",
    "f.close()\n",
    "\n",
    "f = open(\"./data/GSM8K/gsm3k_code.jsonl\", \"r\")\n",
    "for line in f:\n",
    "    line = json.loads(line)\n",
    "    line[\"question\"] = normalize(line[\"question\"])\n",
    "    code_data.append(line)\n",
    "\n",
    "f.close()\n",
    "\n",
    "final_data = []\n",
    "for s1 in code_data:\n",
    "    new_sample = {\n",
    "        \"question\": s1[\"question\"],\n",
    "        \"instruction\": s1[\"instruction\"],\n",
    "        \"code\": s1[\"code\"],\n",
    "        \"answer\": None\n",
    "    }\n",
    "    for s2 in data:\n",
    "        if s1[\"question\"] == s2[\"question\"]:\n",
    "            new_sample[\"answer\"] = s2[\"answer\"]\n",
    "            break \n",
    "    final_data.append(new_sample)\n",
    "\n",
    "for i, s in enumerate(final_data):\n",
    "    if s[\"answer\"] is None:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8929"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Define the number of clips sold in April\n",
      "clips_april = 48\n",
      "\n",
      "# Divide the number of clips sold in April by 2 to calculate the number of clips sold in May\n",
      "clips_may = clips_april / 2\n",
      "\n",
      "# Add the number of clips sold in April and the number of clips sold in May to calculate the total number of clips sold in April and May\n",
      "clips_total = clips_april + clips_may\n",
      "\n",
      "# Print the total number of clips sold in April and May\n",
      "print(clips_total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((final_data[0][\"code\"])[9:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.python_executor import PythonExecutor\n",
    "import re\n",
    "\n",
    "CODE_PATTERN = re.compile(r\"```python([\\s\\S]*)```\")\n",
    "\n",
    "def extract_code(s: str):\n",
    "    return CODE_PATTERN.findall(s)[0]\n",
    "\n",
    "executor = PythonExecutor(get_answer_from_stdout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 8126/8929 [15:28<01:31,  8.74it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import  tqdm\n",
    "final_data_1 = []\n",
    "for s in tqdm(final_data):\n",
    "    try:\n",
    "        code = extract_code(s[\"code\"])\n",
    "        predictions = float(executor.apply(code)[0])\n",
    "    except:\n",
    "        continue\n",
    "    if abs(predictions - s[\"answer\"]) < 1e-5:\n",
    "        final_data_1.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6648"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/GSM8K/gsm8k_code.jsonl\", \"a\") as f:\n",
    "    for s in final_data_1:\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'instruction': 'STEP\\nStep 1: The number of clips sold in April is 48.\\nStep 2: Divide the number of clips sold in April by 2 to calculate the number of clips sold in May.\\nStep 3: Add the number of clips sold in April and the number of clips sold in May to calculate the total number of clips sold in April and May.',\n",
       " 'code': '```python\\n# Define the number of clips sold in April\\nclips_april = 48\\n\\n# Divide the number of clips sold in April by 2 to calculate the number of clips sold in May\\nclips_may = clips_april / 2\\n\\n# Add the number of clips sold in April and the number of clips sold in May to calculate the total number of clips sold in April and May\\nclips_total = clips_april + clips_may\\n\\n# Print the total number of clips sold in April and May\\nprint(clips_total)\\n```',\n",
       " 'answer': 72.0}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?',\n",
       " 'instruction': 'STEP\\nStep 1: The amount Weng earns per hour babysitting is $12.\\nStep 2: Calculate how much Weng earns per minute babysitting by dividing the amount Weng earns per hour by 60. In this case, $12 divided by 60 equals $0.20 per minute.\\nStep 3: Multiply the result in step 2 by 50 to find the amount of money Weng earns after 50 minutes of babysitting. In this case, $0.20 multiplied by 50 equals $10.',\n",
       " 'code': '```python\\n# Define the amount Weng earns per hour babysitting\\nhourly_rate = 12\\n\\n# Calculate how much Weng earns per minute babysitting by dividing the hourly rate by 60\\nminute_rate = hourly_rate / 60\\n\\n# Multiply the minute rate by 50 to find the amount of money Weng earns after 50 minutes of babysitting\\nearnings = minute_rate * 50\\n\\n# Print the earnings\\nprint(earnings)\\n```',\n",
       " 'answer': 10.0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6648/6648 [00:00<00:00, 27024.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import  tqdm\n",
    "with open(\"./data/gsm8k_zalo/gsm8k_v1.jsonl\", \"a\") as f:\n",
    "    for sample in tqdm(final_data_1):\n",
    "        code = f\"```python\\n{extract_code(sample['code'])}\\n```\"\n",
    "        s = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Solve the following problem: {sample['question']}\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": (\n",
    "                        \"Let's break it down step by step first:\\n\"\n",
    "                        f\"{sample['instruction']}\\n\"\n",
    "                        \"Here's the Python code based on the plan above:\\n\"\n",
    "                        f\"{code}\"    \n",
    "                    )\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZALO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "def normalize(s: str):\n",
    "    return unicodedata.normalize(\"NFC\", s)\n",
    "\n",
    "    \n",
    "f  = open(\"./data/zalo/train/math_code_v2.jsonl\")\n",
    "code_data = []\n",
    "for line in f:\n",
    "    line = json.loads(line.strip())\n",
    "    code_data.append(line)\n",
    "f.close()\n",
    "\n",
    "with open(\"./data/zalo/train/math_train.json\", \"r\") as f:\n",
    "    original_data = json.loads(f.read())\n",
    "\n",
    "for sample in code_data:\n",
    "    sample[\"answer\"] = None\n",
    "    for sample_1 in original_data[\"data\"]:\n",
    "        question = normalize(sample[\"question\"].strip())\n",
    "        question_1 = normalize(sample_1[\"question\"].strip())\n",
    "        if question_1[:-1] in question:\n",
    "            sample[\"answer\"] = normalize(sample_1[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1208"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import  tqdm\n",
    "import re\n",
    "from src.utils.python_executor import PythonExecutor\n",
    "\n",
    "\n",
    "CODE_PATTERN = re.compile(r\"```python([\\s\\S]*)```\")\n",
    "\n",
    "def extract_code(s: str):\n",
    "    return CODE_PATTERN.findall(s)[0]\n",
    "\n",
    "executor = PythonExecutor(get_answer_from_stdout=True)\n",
    "\n",
    "def is_float(string: str):\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "COMPARISON_PATTERN = re.compile(\"if ([\\w]+==.*|[\\w]+ ==.*):\")\n",
    "\n",
    "\n",
    "def fix_rounding_error(code: str):\n",
    "    comparisons = COMPARISON_PATTERN.findall(code)\n",
    "    if len(comparisons) == 0:\n",
    "        return code\n",
    "    answer_variable = comparisons[0].split(\"==\")[0]\n",
    "    answer_value = executor.apply(\n",
    "        code + f\"\\nprint({answer_variable})\"\n",
    "    )[0]\n",
    "    if is_float(answer_value):\n",
    "        for comparison in comparisons:\n",
    "            choice_variable = comparison.split(\"==\")[-1]\n",
    "            str_to_replace = f\"abs({answer_variable}-{choice_variable}) < 1e-8\"\n",
    "            code = code.replace(comparison, str_to_replace)\n",
    "    \n",
    "    return code\n",
    "\n",
    "def execute_python_code(code: str):\n",
    "    output = executor.apply(code)\n",
    "    if output[1] == 'Done':\n",
    "        if output[0] == '':\n",
    "            return code, \"Missing print function!!!!\"\n",
    "        if output[0].strip() not in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "            code = fix_rounding_error(code)\n",
    "            output = executor.apply(code)        \n",
    "\n",
    "    return code, output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [03:12<00:00,  6.27it/s]\n"
     ]
    }
   ],
   "source": [
    "code_data_1 = []\n",
    "drop_ids = []\n",
    "for i, s in enumerate(tqdm(code_data)):\n",
    "    try:\n",
    "        code = extract_code(s[\"code\"])\n",
    "    except:\n",
    "        drop_ids.append(i)\n",
    "        continue\n",
    "    tmp = execute_python_code(code)\n",
    "    _, output = tmp\n",
    "    if output.strip().lower() == s[\"answer\"][0].lower():\n",
    "        code_data_1.append(s)\n",
    "    else:\n",
    "        drop_ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/zalo/train/zalo_code_filtered.jsonl\", \"a\") as f:\n",
    "    for s in code_data_1:\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Một người bán hàng bỏ ra 80,000 đồng tiền vốn và bị lỗ 6%. Để tính số tiền lỗ ta phải tính?\\nA. 80,000 : 6\\nB. 80,000 x 6\\nC. 80,000 : (6 x 100)\\nD. (80,000 x 6) : 100\\n',\n",
       " 'instruction': 'STEP\\nStep 1: The capital invested is 80,000 VND, and the loss percentage is 6%.\\nStep 2: To calculate the loss amount, multiply the initial capital amount (80,000) by the loss percentage (6%).\\nStep 3: Compare the calculated results with each answer to choose the correct answer.',\n",
       " 'code': 'I can try to write a Python code based on the instructions you gave me. Here is what I came up with:\\n\\n```python\\ninitial_capital = 80000\\nloss_percentage = 6 / 100\\n\\nloss = initial_capital * loss_percentage\\n\\nanswers = {\\n    \"A\": 80000 / 6,\\n    \"B\": 80000 * 6,\\n    \"C\": 80000 / (6 * 100),\\n    \"D\": (80000 * 6) / 100\\n}\\nif loss == answers[\"A\"]:\\n    answer = \"A\"\\nelif loss == answers[\"B\"]:\\n    answer = \"B\"\\nelif loss == answers[\"C\"]:\\n    answer = \"C\"\\nelif loss == answers[\"D\"]:\\n    answer = \"D\"\\nelse:\\n    answer = \"No answer\"\\n\\nprint(answer)\\n```\\n\\nThe correct answer is **D**.',\n",
       " 'answer': 'D. (80,000 x 6) : 100'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_data_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [00:00<00:00, 16837.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import  tqdm\n",
    "import json\n",
    "\n",
    "from src.utils.utils import add_notes\n",
    "\n",
    "with open(\"./data/gsm8k_zalo/zalo_v1.jsonl\", \"a\") as f:\n",
    "    for sample in tqdm(code_data_1):\n",
    "        code = f\"```python\\n{extract_code(sample['code'])}\\n```\"\n",
    "        question = add_notes(sample['question'])\n",
    "        s = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Solve the following multiple-choices problem: {question}\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": (\n",
    "                        \"Let's break it down step by step first:\\n\"\n",
    "                        f\"{sample['instruction']}\\n\"\n",
    "                        \"Here's the Python code based on the plan above:\\n\"\n",
    "                        f\"{code}\"    \n",
    "                    )\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP\n",
      "Step 1: Convert 10% to decimal form by dividing it by 100.\n",
      "Step 2: Multiply the decimal form of 10% by 5 dm to find the answer.\n",
      "Step 3: Compare the calculated result with each answer to choose the correct option.\n"
     ]
    }
   ],
   "source": [
    "print(code_data[5][\"instruction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 7,\n",
       " 18,\n",
       " 20,\n",
       " 24,\n",
       " 31,\n",
       " 36,\n",
       " 39,\n",
       " 40,\n",
       " 43,\n",
       " 45,\n",
       " 51,\n",
       " 53,\n",
       " 57,\n",
       " 66,\n",
       " 69,\n",
       " 73,\n",
       " 85,\n",
       " 86,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 93,\n",
       " 95,\n",
       " 97,\n",
       " 99,\n",
       " 101,\n",
       " 104,\n",
       " 110,\n",
       " 119,\n",
       " 131,\n",
       " 134,\n",
       " 137,\n",
       " 149,\n",
       " 150,\n",
       " 154,\n",
       " 158,\n",
       " 165,\n",
       " 166,\n",
       " 171,\n",
       " 174,\n",
       " 181,\n",
       " 182,\n",
       " 190,\n",
       " 197,\n",
       " 199,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 216,\n",
       " 229,\n",
       " 233,\n",
       " 234,\n",
       " 242,\n",
       " 248,\n",
       " 249,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 260,\n",
       " 263,\n",
       " 264,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 271,\n",
       " 275,\n",
       " 277,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 285,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 293,\n",
       " 296,\n",
       " 297,\n",
       " 299,\n",
       " 302,\n",
       " 307,\n",
       " 310,\n",
       " 311,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 321,\n",
       " 322,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 329,\n",
       " 330,\n",
       " 332,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 342,\n",
       " 346,\n",
       " 348,\n",
       " 350,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 360,\n",
       " 361,\n",
       " 363,\n",
       " 364,\n",
       " 374,\n",
       " 383,\n",
       " 384,\n",
       " 387,\n",
       " 389,\n",
       " 395,\n",
       " 396,\n",
       " 399,\n",
       " 407,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 421,\n",
       " 429,\n",
       " 431,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 440,\n",
       " 442,\n",
       " 447,\n",
       " 452,\n",
       " 453,\n",
       " 459,\n",
       " 460,\n",
       " 465,\n",
       " 469,\n",
       " 471,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 480,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 491,\n",
       " 492,\n",
       " 494,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 507,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 514,\n",
       " 515,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 547,\n",
       " 549,\n",
       " 552,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 559,\n",
       " 560,\n",
       " 563,\n",
       " 565,\n",
       " 572,\n",
       " 574,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 583,\n",
       " 584,\n",
       " 589,\n",
       " 591,\n",
       " 593,\n",
       " 596,\n",
       " 598,\n",
       " 599,\n",
       " 607,\n",
       " 610,\n",
       " 611,\n",
       " 615,\n",
       " 619,\n",
       " 624,\n",
       " 625,\n",
       " 629,\n",
       " 633,\n",
       " 640,\n",
       " 643,\n",
       " 647,\n",
       " 648,\n",
       " 652,\n",
       " 654,\n",
       " 655,\n",
       " 659,\n",
       " 661,\n",
       " 662,\n",
       " 664,\n",
       " 673,\n",
       " 683,\n",
       " 685,\n",
       " 692,\n",
       " 700,\n",
       " 710,\n",
       " 715,\n",
       " 721,\n",
       " 723,\n",
       " 724,\n",
       " 727,\n",
       " 730,\n",
       " 732,\n",
       " 734,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 752,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 758,\n",
       " 760,\n",
       " 763,\n",
       " 766,\n",
       " 770,\n",
       " 772,\n",
       " 775,\n",
       " 778,\n",
       " 780,\n",
       " 782,\n",
       " 783,\n",
       " 785,\n",
       " 791,\n",
       " 795,\n",
       " 798,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 807,\n",
       " 809,\n",
       " 811,\n",
       " 815,\n",
       " 816,\n",
       " 818,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 832,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 853,\n",
       " 854,\n",
       " 867,\n",
       " 874,\n",
       " 878,\n",
       " 879,\n",
       " 881,\n",
       " 886,\n",
       " 887,\n",
       " 891,\n",
       " 909,\n",
       " 924,\n",
       " 925,\n",
       " 927,\n",
       " 932,\n",
       " 943,\n",
       " 948,\n",
       " 951,\n",
       " 957,\n",
       " 962,\n",
       " 964,\n",
       " 965,\n",
       " 967,\n",
       " 969,\n",
       " 970,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 977,\n",
       " 979,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 987,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 995,\n",
       " 998,\n",
       " 999,\n",
       " 1000,\n",
       " 1001,\n",
       " 1004,\n",
       " 1007,\n",
       " 1009,\n",
       " 1011,\n",
       " 1015,\n",
       " 1019,\n",
       " 1026,\n",
       " 1029,\n",
       " 1030,\n",
       " 1032,\n",
       " 1033,\n",
       " 1034,\n",
       " 1035,\n",
       " 1037,\n",
       " 1038,\n",
       " 1043,\n",
       " 1044,\n",
       " 1046,\n",
       " 1047,\n",
       " 1049,\n",
       " 1051,\n",
       " 1054,\n",
       " 1060,\n",
       " 1063,\n",
       " 1064,\n",
       " 1067,\n",
       " 1068,\n",
       " 1069,\n",
       " 1073,\n",
       " 1080,\n",
       " 1081,\n",
       " 1082,\n",
       " 1088,\n",
       " 1090,\n",
       " 1091,\n",
       " 1094,\n",
       " 1097,\n",
       " 1102,\n",
       " 1103,\n",
       " 1106,\n",
       " 1122,\n",
       " 1123,\n",
       " 1124,\n",
       " 1127,\n",
       " 1128,\n",
       " 1130,\n",
       " 1131,\n",
       " 1135,\n",
       " 1137,\n",
       " 1141,\n",
       " 1142,\n",
       " 1143,\n",
       " 1147,\n",
       " 1150,\n",
       " 1151,\n",
       " 1154,\n",
       " 1156,\n",
       " 1157,\n",
       " 1160,\n",
       " 1161,\n",
       " 1162,\n",
       " 1164,\n",
       " 1166,\n",
       " 1168,\n",
       " 1172,\n",
       " 1173,\n",
       " 1174,\n",
       " 1175,\n",
       " 1176,\n",
       " 1178,\n",
       " 1181,\n",
       " 1182,\n",
       " 1184,\n",
       " 1188,\n",
       " 1197,\n",
       " 1198,\n",
       " 1201,\n",
       " 1204,\n",
       " 1205]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_id = [5, 7, 36, 43, 53, 66, 69, 73, 85, 86, 89, 90, 93, 97, 99, 101, 104, 110, 119]\n",
    "correct_id = [91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Một ô tô đi từ Hà Nội lúc 11 giờ trưa và đến Vinh lúc 5 giờ 30 phút chiều. Dọc đường ô tô dừng ở Ninh Bình và Thanh Hóa mỗi nơi 15 phút. Hỏi không kể thời gian dừng dọc đường, ô tô đi hết quãng đường từ Hà Nội đến Vinh mất bao nhiêu thời gian ?\n",
      "A. 4 giờ 30 phút\n",
      "B. 6 giờ 30 phút\n",
      "C. 6 giờ 15 phút\n",
      "D. 6 giờ\n",
      "\n",
      "STEP\n",
      "Step 1: Calculate the total time spent on the road by subtracting the time of departure from the time of arrival. \n",
      "Step 2: Subtract the time spent at each stop (Ninh Binh and Thanh Hoa) from the total time calculated in step 1. \n",
      "Step 3: Compare the results with the answers to find the correct option.\n",
      "D. 6 giờ\n"
     ]
    }
   ],
   "source": [
    "ind = 1205\n",
    "print(code_data[ind][\"question\"])\n",
    "print(code_data[ind][\"instruction\"])\n",
    "print(code_data[ind][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE\n",
      "```python\n",
      "departure_time = 11  # in hours\n",
      "arrival_time = 5 + 30/60  # in hours\n",
      "\n",
      "total_time_on_road = arrival_time - departure_time\n",
      "\n",
      "# Time spent at each stop in hours\n",
      "stop_time = 15 / 60\n",
      "\n",
      "# Subtract stop time from the total time on the road\n",
      "total_time_without_stops = total_time_on_road - (2 * stop_time)\n",
      "\n",
      "answers = {\n",
      "    \"A\": 4 + 30/60,\n",
      "    \"B\": 6 + 30/60,\n",
      "    \"C\": 6 + 15/60,\n",
      "    \"D\": 6\n",
      "}\n",
      "if total_time_without_stops == answers[\"A\"]:\n",
      "    answer = \"A\"\n",
      "elif total_time_without_stops == answers[\"B\"]:\n",
      "    answer = \"B\"\n",
      "elif total_time_without_stops == answers[\"C\"]:\n",
      "    answer = \"C\"\n",
      "elif total_time_without_stops == answers[\"D\"]:\n",
      "    answer = \"D\"\n",
      "else:\n",
      "    answer = \"No answer\"\n",
      "\n",
      "print(answer)\n",
      "```\n",
      "\n",
      "This code calculates the total time spent on the road without considering the time spent at stops in Ninh Binh and Thanh Hoa. It then compares this result with the provided answer choices to determine the correct option.\n"
     ]
    }
   ],
   "source": [
    "print(code_data[ind][\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    }
   ],
   "source": [
    "x = (27 * 8) / 3\n",
    "\n",
    "answers = {\n",
    "    \"A\": 56,\n",
    "    \"B\": 64,\n",
    "    \"C\": 72,\n",
    "    \"D\": 80\n",
    "}\n",
    "if x == answers[\"A\"]:\n",
    "    answer = \"A\"\n",
    "elif x == answers[\"B\"]:\n",
    "    answer = \"B\"\n",
    "elif x == answers[\"C\"]:\n",
    "    answer = \"C\"\n",
    "elif x == answers[\"D\"]:\n",
    "    answer = \"D\"\n",
    "else:\n",
    "    answer = \"No answer\"\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI_GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import unicodedata\n",
    "\n",
    "def normalize(s: str):\n",
    "    return unicodedata.normalize(\"NFC\", s)\n",
    "\n",
    "f = open(\"./data/GSM8K/gsm8k_vi.jsonl\", \"r\")\n",
    "vi_data = []\n",
    "for line in f:\n",
    "    line = json.loads(line)\n",
    "    for sample in line:\n",
    "        sample[\"question\"] = normalize(sample[\"query\"])\n",
    "        answer = normalize(sample[\"response\"]).split(\"####\")[-1]\n",
    "        try:\n",
    "            sample[\"answer\"] = float(answer.replace(\",\", \"\").strip())\n",
    "            vi_data.append(sample)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "f.close()\n",
    "\n",
    "f = open(\"./data/GSM8K/train.jsonl\", \"r\")\n",
    "en_data = []\n",
    "for line in f:\n",
    "    line = json.loads(line)\n",
    "    line[\"question\"] = normalize(line[\"question\"])\n",
    "    line[\"answer\"] = normalize(line[\"answer\"])\n",
    "    en_data.append(line)\n",
    "\n",
    "f.close()\n",
    "\n",
    "f = open(\"./data/GSM8K/test.jsonl\", \"r\")\n",
    "for line in f:\n",
    "    line = json.loads(line)\n",
    "    line[\"question\"] = normalize(line[\"question\"])\n",
    "    line[\"answer\"] = normalize(line[\"answer\"])\n",
    "    en_data.append(line)\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s1 in vi_data:\n",
    "    s1[\"en_question\"] = None\n",
    "    for s2 in en_data:\n",
    "        if s1[\"response\"] == s2[\"answer\"]:\n",
    "            s1[\"en_question\"] = s2[\"question\"]\n",
    "            break\n",
    "\n",
    "for i, s1 in enumerate(vi_data):\n",
    "    if not s1[\"en_question\"]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./data/GSM8K/gsm8k_code.jsonl\", \"r\")\n",
    "code_data = []\n",
    "for line in f:\n",
    "    line = json.loads(line)\n",
    "    line[\"question\"] = normalize(line[\"question\"])\n",
    "    code_data.append(line)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6648"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s1 in vi_data:\n",
    "    s1[\"code\"] = None\n",
    "    for s2 in code_data:\n",
    "        if s1[\"en_question\"] == s2[\"question\"]:\n",
    "            s1[\"code\"] = s2[\"code\"]\n",
    "            s1[\"instruction\"] = s2[\"instruction\"]\n",
    "            break\n",
    "\n",
    "vi_data_1 = []\n",
    "for i, s1 in enumerate(vi_data):\n",
    "    if s1[\"code\"]:\n",
    "        vi_data_1.append(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/GSM8K/vi_gsm8k_code.jsonl\", \"a\") as f:\n",
    "    for s in vi_data_1:\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "CODE_PATTERN = re.compile(r\"```python([\\s\\S]*)```\")\n",
    "\n",
    "def extract_code(s: str):\n",
    "    return CODE_PATTERN.findall(s)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Natalia đã bán clip cho 48 người bạn của mình vào tháng 4 và sau đó cô đã bán được một nửa số clip đó vào tháng 5. Natalia đã bán được tổng cộng bao nhiêu clip trong tháng 4 và tháng 5?',\n",
       " 'response': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72',\n",
       " 'question': 'Natalia đã bán clip cho 48 người bạn của mình vào tháng 4 và sau đó cô đã bán được một nửa số clip đó vào tháng 5. Natalia đã bán được tổng cộng bao nhiêu clip trong tháng 4 và tháng 5?',\n",
       " 'answer': 72.0,\n",
       " 'en_question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'code': '```python\\n# Define the number of clips sold in April\\nclips_april = 48\\n\\n# Divide the number of clips sold in April by 2 to calculate the number of clips sold in May\\nclips_may = clips_april / 2\\n\\n# Add the number of clips sold in April and the number of clips sold in May to calculate the total number of clips sold in April and May\\nclips_total = clips_april + clips_may\\n\\n# Print the total number of clips sold in April and May\\nprint(clips_total)\\n```',\n",
       " 'instruction': 'STEP\\nStep 1: The number of clips sold in April is 48.\\nStep 2: Divide the number of clips sold in April by 2 to calculate the number of clips sold in May.\\nStep 3: Add the number of clips sold in April and the number of clips sold in May to calculate the total number of clips sold in April and May.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_data_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5756/5756 [00:00<00:00, 25200.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import  tqdm\n",
    "\n",
    "with open(\"./data/gsm8k_zalo/vi_gsm8k_v1.jsonl\", \"a\") as f:\n",
    "    for sample in tqdm(vi_data_1):\n",
    "        code = f\"```python\\n{extract_code(sample['code'])}\\n```\"\n",
    "        s = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Solve the following problem: {sample['question']}\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": (\n",
    "                        \"Let's break it down step by step first:\\n\"\n",
    "                        f\"{sample['instruction']}\\n\"\n",
    "                        \"Here's the Python code based on the plan above:\\n\"\n",
    "                        f\"{code}\"    \n",
    "                    )\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EN_ZALO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import unicodedata\n",
    "\n",
    "def normalize(s: str):\n",
    "    return unicodedata.normalize(\"NFC\", s)\n",
    "\n",
    "f = open(\"./data/zalo/train/math_train_en.jsonl\", \"r\")\n",
    "en_data = []\n",
    "for line in f:\n",
    "    line = json.loads(line)\n",
    "    for sample in line:\n",
    "        sample[\"question\"] = normalize(sample[\"question\"])\n",
    "        en_data.append(sample)\n",
    "\n",
    "f.close()\n",
    "\n",
    "\n",
    "with open(\"./data/zalo/train/math_train.json\", \"r\") as f:\n",
    "    vi_data = json.loads(f.read())[\"data\"]\n",
    "\n",
    "for s in vi_data:\n",
    "    s[\"question\"] = normalize(s[\"question\"])\n",
    "\n",
    "code_data = []\n",
    "with open(\"./data/zalo/train/zalo_code_filtered.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        code_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s1 in en_data:\n",
    "    s1[\"vi_question\"] = None\n",
    "    for s2 in vi_data:\n",
    "        if s1[\"id\"] == s2[\"id\"]:\n",
    "            s1[\"vi_question\"] = normalize(s2[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_words = [\"số bị trừ\", \"số trừ\", \"số hạng\", \"thừa số\", \"số bị chia\", \"số chia\", \"giao hoán\", \"tính kết hợp\", \"tính chất kết hợp\"]\n",
    "def contain_ban_word(s: str):\n",
    "    for w in ban_words:\n",
    "        if w in s:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for s1 in en_data:\n",
    "    s1[\"instruction\"] = None\n",
    "    s1[\"code\"] = None\n",
    "    for s2 in code_data:\n",
    "        if s1[\"vi_question\"][:-4] in s2[\"question\"] and not contain_ban_word(s1[\"vi_question\"]): \n",
    "            s1[\"instruction\"] = s2[\"instruction\"]\n",
    "            s1[\"code\"] = s2[\"code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data_1 = []\n",
    "for s in en_data:\n",
    "    if s[\"instruction\"]:\n",
    "        en_data_1.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/zalo/train/zalo_code_en.jsonl\", \"a\") as f:\n",
    "    for s in en_data_1:\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "CODE_PATTERN = re.compile(r\"```python([\\s\\S]*)```\")\n",
    "\n",
    "def extract_code(s: str):\n",
    "    return CODE_PATTERN.findall(s)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:00<00:00, 32864.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import  tqdm\n",
    "import json\n",
    "\n",
    "with open(\"./data/gsm8k_zalo/en_zalo_v1.jsonl\", \"a\") as f:\n",
    "    for sample in tqdm(en_data_1):\n",
    "        code = f\"```python\\n{extract_code(sample['code'])}\\n```\"\n",
    "        question = sample[\"question\"]\n",
    "        s = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Solve the following multiple-choices problem: {question}\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": (\n",
    "                        \"Let's break it down step by step first:\\n\"\n",
    "                        f\"{sample['instruction']}\\n\"\n",
    "                        \"Here's the Python code based on the plan above:\\n\"\n",
    "                        f\"{code}\"    \n",
    "                    )\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METAMATHQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./data/MetaMathQA/MetaMathQA-395K.json\", \"r\") as f:\n",
    "    metamath_data = json.loads(f.read())\n",
    "\n",
    "gsm8k_data = []\n",
    "with open(\"./data/GSM8K/train.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        gsm8k_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Which letter corresponds to the graph of $y = |f(x)|$?',\n",
       " 'response': 'The graph of $y = |f(x)|$ is the graph of $y = f(x)$ reflected across the x-axis for all values of $x$ where $f(x) < 0$.\\nTherefore, the correct letter that corresponds to the graph of $y = |f(x)|$ is the letter $\\\\boxed{\\\\text{D}}$.The answer is: \\\\text{D}',\n",
       " 'type': 'MATH_Rephrased'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metamath_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GSM_Rephrased', 'MATH_FOBAR', 'GSM_FOBAR', 'MATH_AnsAug', 'MATH_SV', 'GSM_SV', 'MATH_Rephrased', 'GSM_AnsAug'}\n"
     ]
    }
   ],
   "source": [
    "types = set()\n",
    "for s in metamath_data:\n",
    "    types.add(s[\"type\"])\n",
    "\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395000/395000 [00:00<00:00, 2160396.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "gsm8k_new = []\n",
    "for s in tqdm(metamath_data):\n",
    "    if \"GSM\" in s[\"type\"]:\n",
    "        gsm8k_new.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gsm8k_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Jerry has to shingle 3 roofs. Each roof consists of two slanted rectangular sides that measure 20 feet by 40 feet. If he requires 8 shingles to cover one square foot of roof, what is the total number of shingles he needs?',\n",
       " 'response': 'The area of one side of the roof is 20 feet x 40 feet = 800 square feet\\nSince there are two sides to each roof, the total area of one roof is 800 square feet x 2 = 1600 square feet\\nJerry needs 8 shingles to cover 1 square foot, so to cover 1600 square feet he will need 1600 square feet x 8 shingles/square foot = 12800 shingles\\nSince he has to shingle 3 roofs, the total number of shingles he needs is 12800 shingles x 3 roofs = 38400 shingles\\n#### 38400\\nThe answer is: 38400',\n",
       " 'type': 'GSM_Rephrased'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm8k_new[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395000/395000 [03:29<00:00, 1888.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for s1 in tqdm(metamath_data):\n",
    "    if \"GSM\" not in s1[\"type\"]:\n",
    "        continue\n",
    "    for s2 in gsm8k_data:\n",
    "        if s1[\"response\"]==s2[\"answer\"] and s1[\"query\"]!=s2[\"question\"]:\n",
    "            gsm8k_data.append({\n",
    "                \"question\": s1[\"query\"],\n",
    "                \"answer\": s1[\"response\"]\n",
    "            })\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s: str):\n",
    "    return unicodedata.normalize(\"NFC\", s)\n",
    "\n",
    "f = open(\"./data/GSM8K/train.jsonl\", \"r\")\n",
    "data = []\n",
    "for line in f:\n",
    "    line = json.loads(line)\n",
    "    line[\"question\"] = normalize(line[\"question\"])\n",
    "    answer = normalize(line[\"answer\"]).split(\"####\")[-1]\n",
    "    line[\"answer\"] = float(answer.replace(\",\", \"\").strip())\n",
    "    data.append(line)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7473"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = set()\n",
    "for s in data:\n",
    "    answers.add(s[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-based few shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zalo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from src.utils.preprocess import  preprocess\n",
    "from copy import  deepcopy\n",
    "\n",
    "zalo_code = []\n",
    "with open(\"data/zalo/train/zalo_code_filtered.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        zalo_code.append(json.loads(line))\n",
    "\n",
    "question_corpus = []\n",
    "for s in zalo_code:\n",
    "    question = s[\"question\"].split(\"\\n\")[0]\n",
    "    question_corpus.append(question.lower())\n",
    "\n",
    "#-----------------------------------------------\n",
    "\n",
    "WORD_PATTERN = re.compile(r\"[\\w]+\")\n",
    "NUMBER_PATTERN = re.compile(r\"[\\d]+\")\n",
    "\n",
    "def remove_numbers(s: str):\n",
    "    return NUMBER_PATTERN.sub(\"\", s)\n",
    "\n",
    "question_corpus = list(map(preprocess, tqdm(question_corpus)))\n",
    "tokenized_question_corpus = list(map(\n",
    "    lambda s: WORD_PATTERN.findall(remove_numbers(s)), \n",
    "    tqdm(question_corpus)\n",
    "))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_question_corpus)\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "\n",
    "new_zalo_code = []\n",
    "for s in zalo_code:\n",
    "    question = s[\"question\"].split(\"\\n\")[0]\n",
    "    question = preprocess(question, lowercase=True)\n",
    "    tokenized_ques = WORD_PATTERN.findall(remove_numbers(question))\n",
    "    new_s = deepcopy(s)\n",
    "    new_s[\"examples\"] = bm25.get_top_n(tokenized_ques, zalo_code, n=2)\n",
    "    new_zalo_code.append(new_s)\n",
    "\n",
    "with open(\"./data/zalo/train/zalo_code_filtered_1.jsonl\", \"a\") as f:\n",
    "    for s in new_zalo_code:\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natalia đã bán clip cho 48 người bạn của mình vào tháng 4 và sau đó cô đã bán được một nửa số clip đó vào tháng 5. natalia đã bán được tổng cộng bao nhiêu clip trong tháng 4 và tháng 5?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "zalo_code = []\n",
    "with open(\"data/zalo/train/zalo_code_filtered.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        zalo_code.append(json.loads(line))\n",
    "\n",
    "question_corpus = []\n",
    "for s in zalo_code:\n",
    "    question = s[\"question\"].split(\"\\n\")[0]\n",
    "    question_corpus.append(question.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## en zalo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:00<00:00, 143212.49it/s]\n",
      "100%|██████████| 731/731 [00:00<00:00, 91959.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from src.utils.preprocess import  preprocess\n",
    "from copy import  deepcopy\n",
    "\n",
    "zalo_code = []\n",
    "with open(\"data/zalo/train/zalo_code_en.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        zalo_code.append(json.loads(line))\n",
    "\n",
    "question_corpus = []\n",
    "for s in zalo_code:\n",
    "    question = s[\"question\"].split(\"\\n\")[0]\n",
    "    question_corpus.append(question.lower())\n",
    "\n",
    "#-----------------------------------------------\n",
    "\n",
    "WORD_PATTERN = re.compile(r\"[\\w]+\")\n",
    "NUMBER_PATTERN = re.compile(r\"[\\d]+\")\n",
    "\n",
    "def remove_numbers(s: str):\n",
    "    return NUMBER_PATTERN.sub(\"\", s)\n",
    "\n",
    "question_corpus = list(map(preprocess, tqdm(question_corpus)))\n",
    "tokenized_question_corpus = list(map(\n",
    "    lambda s: WORD_PATTERN.findall(remove_numbers(s)), \n",
    "    tqdm(question_corpus)\n",
    "))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_question_corpus)\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "\n",
    "new_zalo_code = []\n",
    "for s in zalo_code:\n",
    "    question = s[\"question\"].split(\"\\n\")[0]\n",
    "    question = preprocess(question, lowercase=True)\n",
    "    tokenized_ques = WORD_PATTERN.findall(remove_numbers(question))\n",
    "    new_s = deepcopy(s)\n",
    "    new_s[\"examples\"] = bm25.get_top_n(tokenized_ques, zalo_code, n=2)\n",
    "    new_zalo_code.append(new_s)\n",
    "\n",
    "with open(\"./data/zalo/train/zalo_code_en_1.jsonl\", \"a\") as f:\n",
    "    for s in new_zalo_code:\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gsm8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6648/6648 [00:00<00:00, 197377.61it/s]\n",
      "100%|██████████| 6648/6648 [00:00<00:00, 39603.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from src.utils.preprocess import  preprocess\n",
    "from copy import  deepcopy\n",
    "\n",
    "gsm8k_code = []\n",
    "with open(\"data/GSM8K/gsm8k_code.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        gsm8k_code.append(json.loads(line))\n",
    "\n",
    "question_corpus = []\n",
    "for s in gsm8k_code:\n",
    "    question = s[\"question\"].split(\"\\n\")[0]\n",
    "    question_corpus.append(question.lower())\n",
    "\n",
    "#-----------------------------------------------\n",
    "\n",
    "WORD_PATTERN = re.compile(r\"[\\w]+\")\n",
    "NUMBER_PATTERN = re.compile(r\"[\\d]+\")\n",
    "\n",
    "def remove_numbers(s: str):\n",
    "    return NUMBER_PATTERN.sub(\"\", s)\n",
    "\n",
    "question_corpus = list(map(preprocess, tqdm(question_corpus)))\n",
    "tokenized_question_corpus = list(map(\n",
    "    lambda s: WORD_PATTERN.findall(remove_numbers(s)), \n",
    "    tqdm(question_corpus)\n",
    "))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_question_corpus)\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "\n",
    "new_gsm8k_code = []\n",
    "for s in gsm8k_code:\n",
    "    question = s[\"question\"].split(\"\\n\")[0]\n",
    "    question = preprocess(question, lowercase=True)\n",
    "    tokenized_ques = WORD_PATTERN.findall(remove_numbers(question))\n",
    "    new_s = deepcopy(s)\n",
    "    new_s[\"examples\"] = bm25.get_top_n(tokenized_ques, gsm8k_code, n=2)\n",
    "    new_gsm8k_code.append(new_s)\n",
    "\n",
    "with open(\"./data/GSM8K/gsm8k_code_1.jsonl\", \"a\") as f:\n",
    "    for s in new_gsm8k_code:\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vi gsm8k code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5756/5756 [00:00<00:00, 98169.03it/s]\n",
      "100%|██████████| 5756/5756 [00:00<00:00, 46041.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from src.utils.preprocess import  preprocess\n",
    "from copy import  deepcopy\n",
    "\n",
    "gsm8k_code = []\n",
    "with open(\"data/GSM8K/vi_gsm8k_code.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        gsm8k_code.append(json.loads(line))\n",
    "\n",
    "question_corpus = []\n",
    "for s in gsm8k_code:\n",
    "    question = s[\"question\"].split(\"\\n\")[0]\n",
    "    question_corpus.append(question.lower())\n",
    "\n",
    "#-----------------------------------------------\n",
    "\n",
    "WORD_PATTERN = re.compile(r\"[\\w]+\")\n",
    "NUMBER_PATTERN = re.compile(r\"[\\d]+\")\n",
    "\n",
    "def remove_numbers(s: str):\n",
    "    return NUMBER_PATTERN.sub(\"\", s)\n",
    "\n",
    "question_corpus = list(map(preprocess, tqdm(question_corpus)))\n",
    "tokenized_question_corpus = list(map(\n",
    "    lambda s: WORD_PATTERN.findall(remove_numbers(s)), \n",
    "    tqdm(question_corpus)\n",
    "))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_question_corpus)\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "\n",
    "new_gsm8k_code = []\n",
    "for s in gsm8k_code:\n",
    "    question = s[\"question\"].split(\"\\n\")[0]\n",
    "    question = preprocess(question, lowercase=True)\n",
    "    tokenized_ques = WORD_PATTERN.findall(remove_numbers(question))\n",
    "    new_s = deepcopy(s)\n",
    "    new_s[\"examples\"] = bm25.get_top_n(tokenized_ques, gsm8k_code, n=2)\n",
    "    new_gsm8k_code.append(new_s)\n",
    "\n",
    "with open(\"./data/GSM8K/vi_gsm8k_code_1.jsonl\", \"a\") as f:\n",
    "    for s in new_gsm8k_code:\n",
    "        d = json.dumps(s, ensure_ascii=False)+\"\\n\"\n",
    "        f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import  tqdm\n",
    "import re\n",
    "from src.utils.python_executor import PythonExecutor\n",
    "\n",
    "\n",
    "CODE_PATTERN = re.compile(r\"```python([\\s\\S]*)```\")\n",
    "\n",
    "def extract_code(s: str):\n",
    "    return CODE_PATTERN.findall(s)[0]\n",
    "\n",
    "executor = PythonExecutor(get_answer_from_stdout=True)\n",
    "\n",
    "def is_float(string: str):\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "COMPARISON_PATTERN = re.compile(\"if ([\\w]+==.*|[\\w]+ ==.*):\")\n",
    "\n",
    "\n",
    "def fix_rounding_error(code: str):\n",
    "    comparisons = COMPARISON_PATTERN.findall(code)\n",
    "    if len(comparisons) == 0:\n",
    "        return code\n",
    "    answer_variable = comparisons[0].split(\"==\")[0]\n",
    "    answer_value = executor.apply(\n",
    "        code + f\"\\nprint({answer_variable})\"\n",
    "    )[0]\n",
    "    if is_float(answer_value):\n",
    "        for comparison in comparisons:\n",
    "            choice_variable = comparison.split(\"==\")[-1]\n",
    "            str_to_replace = f\"abs({answer_variable}-{choice_variable}) < 1e-8\"\n",
    "            code = code.replace(comparison, str_to_replace)\n",
    "    \n",
    "    return code\n",
    "\n",
    "def execute_python_code(code: str):\n",
    "    output = executor.apply(code)\n",
    "    if output[1] == 'Done':\n",
    "        if output[0] == '':\n",
    "            return code, \"Missing print function!!!!\"\n",
    "        if output[0].strip() not in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "            code = fix_rounding_error(code)\n",
    "            output = executor.apply(code)        \n",
    "\n",
    "    return code, output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "initial_short_side = 8\n",
    "initial_long_side = 12\n",
    "increase_area = 25\n",
    "\n",
    "# Step 2: Write the equation\n",
    "# Step 2 substituted: (8 + x) * 12 = 25 + (8 * 12)\n",
    "# Simplified equation: x * 12 = 25 + (8 * 12)\n",
    "# x = (25 + (8 * 12)) / 12\n",
    "x = (25 + (8 * 12)) / 12\n",
    "\n",
    "# Step 3: Calculate the percentage increase\n",
    "percentage_increase = ((x / 12) * 100)\n",
    "\n",
    "# Step 4: Compare the results with the answers to find the correct option\n",
    "answers = {\n",
    "   \"A\": 125,\n",
    "   \"B\": 20,\n",
    "   \"C\": 25,\n",
    "   \"D\": 50\n",
    "}\n",
    "if percentage_increase == answers[\"A\"]:\n",
    "   answer = \"A\"\n",
    "elif percentage_increase == answers[\"B\"]:\n",
    "   answer = \"B\"\n",
    "elif percentage_increase == answers[\"C\"]:\n",
    "   answer = \"C\"\n",
    "elif percentage_increase == answers[\"D\"]:\n",
    "   answer = \"D\"\n",
    "else:\n",
    "   answer = \"No answer\"\n",
    "\n",
    "print(answer)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, out = execute_python_code(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No answer\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zac2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
